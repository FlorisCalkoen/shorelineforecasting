{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "import project_path\n",
    "from shorelineforecasting.utils.forecasting_metrics import evaluate \n",
    "from shorelineforecasting.utils.configs import GluonConfigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = GluonConfigs.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transects included in dataset: 37111; timesteps: 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1984</th>\n",
       "      <th>1985</th>\n",
       "      <th>1986</th>\n",
       "      <th>1987</th>\n",
       "      <th>1988</th>\n",
       "      <th>1989</th>\n",
       "      <th>1990</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>...</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transect_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BOX_051_151_15</th>\n",
       "      <td>677.32043</td>\n",
       "      <td>695.66370</td>\n",
       "      <td>713.29486</td>\n",
       "      <td>682.1743</td>\n",
       "      <td>688.23425</td>\n",
       "      <td>672.13007</td>\n",
       "      <td>700.43286</td>\n",
       "      <td>693.43460</td>\n",
       "      <td>699.38560</td>\n",
       "      <td>687.97950</td>\n",
       "      <td>...</td>\n",
       "      <td>700.6640</td>\n",
       "      <td>712.41740</td>\n",
       "      <td>708.45123</td>\n",
       "      <td>740.33240</td>\n",
       "      <td>680.42510</td>\n",
       "      <td>758.35150</td>\n",
       "      <td>754.49695</td>\n",
       "      <td>763.04297</td>\n",
       "      <td>743.29680</td>\n",
       "      <td>779.41570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOX_051_151_18</th>\n",
       "      <td>768.93800</td>\n",
       "      <td>769.23883</td>\n",
       "      <td>762.44300</td>\n",
       "      <td>755.8622</td>\n",
       "      <td>761.79663</td>\n",
       "      <td>760.51710</td>\n",
       "      <td>763.30505</td>\n",
       "      <td>761.81360</td>\n",
       "      <td>769.22100</td>\n",
       "      <td>765.47060</td>\n",
       "      <td>...</td>\n",
       "      <td>763.1057</td>\n",
       "      <td>759.72600</td>\n",
       "      <td>766.23150</td>\n",
       "      <td>770.77130</td>\n",
       "      <td>798.26830</td>\n",
       "      <td>797.99615</td>\n",
       "      <td>803.90950</td>\n",
       "      <td>797.90780</td>\n",
       "      <td>798.18830</td>\n",
       "      <td>803.68256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOX_051_151_21</th>\n",
       "      <td>711.41626</td>\n",
       "      <td>684.20540</td>\n",
       "      <td>695.49817</td>\n",
       "      <td>701.6695</td>\n",
       "      <td>705.29990</td>\n",
       "      <td>703.61470</td>\n",
       "      <td>707.69403</td>\n",
       "      <td>692.90360</td>\n",
       "      <td>704.68280</td>\n",
       "      <td>704.99945</td>\n",
       "      <td>...</td>\n",
       "      <td>825.8698</td>\n",
       "      <td>820.51720</td>\n",
       "      <td>820.68680</td>\n",
       "      <td>842.18097</td>\n",
       "      <td>850.45460</td>\n",
       "      <td>775.96700</td>\n",
       "      <td>883.04240</td>\n",
       "      <td>867.92426</td>\n",
       "      <td>877.37415</td>\n",
       "      <td>874.50244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOX_051_151_30</th>\n",
       "      <td>795.81573</td>\n",
       "      <td>820.63700</td>\n",
       "      <td>799.72380</td>\n",
       "      <td>799.8664</td>\n",
       "      <td>823.56260</td>\n",
       "      <td>822.07300</td>\n",
       "      <td>823.56800</td>\n",
       "      <td>823.73300</td>\n",
       "      <td>824.58400</td>\n",
       "      <td>824.33360</td>\n",
       "      <td>...</td>\n",
       "      <td>823.7820</td>\n",
       "      <td>823.15674</td>\n",
       "      <td>823.65790</td>\n",
       "      <td>821.31860</td>\n",
       "      <td>818.85803</td>\n",
       "      <td>817.31220</td>\n",
       "      <td>822.92970</td>\n",
       "      <td>818.73350</td>\n",
       "      <td>822.18480</td>\n",
       "      <td>818.73480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOX_051_151_32</th>\n",
       "      <td>242.70204</td>\n",
       "      <td>238.05159</td>\n",
       "      <td>229.93718</td>\n",
       "      <td>244.0620</td>\n",
       "      <td>247.68105</td>\n",
       "      <td>257.49900</td>\n",
       "      <td>302.69217</td>\n",
       "      <td>301.27722</td>\n",
       "      <td>301.12033</td>\n",
       "      <td>316.40414</td>\n",
       "      <td>...</td>\n",
       "      <td>301.1231</td>\n",
       "      <td>313.63553</td>\n",
       "      <td>313.09814</td>\n",
       "      <td>312.90347</td>\n",
       "      <td>306.18658</td>\n",
       "      <td>294.18326</td>\n",
       "      <td>297.23654</td>\n",
       "      <td>302.88650</td>\n",
       "      <td>323.85840</td>\n",
       "      <td>304.36823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     1984       1985       1986      1987       1988  \\\n",
       "transect_id                                                            \n",
       "BOX_051_151_15  677.32043  695.66370  713.29486  682.1743  688.23425   \n",
       "BOX_051_151_18  768.93800  769.23883  762.44300  755.8622  761.79663   \n",
       "BOX_051_151_21  711.41626  684.20540  695.49817  701.6695  705.29990   \n",
       "BOX_051_151_30  795.81573  820.63700  799.72380  799.8664  823.56260   \n",
       "BOX_051_151_32  242.70204  238.05159  229.93718  244.0620  247.68105   \n",
       "\n",
       "                     1989       1990       1991       1992       1993  ...  \\\n",
       "transect_id                                                            ...   \n",
       "BOX_051_151_15  672.13007  700.43286  693.43460  699.38560  687.97950  ...   \n",
       "BOX_051_151_18  760.51710  763.30505  761.81360  769.22100  765.47060  ...   \n",
       "BOX_051_151_21  703.61470  707.69403  692.90360  704.68280  704.99945  ...   \n",
       "BOX_051_151_30  822.07300  823.56800  823.73300  824.58400  824.33360  ...   \n",
       "BOX_051_151_32  257.49900  302.69217  301.27722  301.12033  316.40414  ...   \n",
       "\n",
       "                    2007       2008       2009       2010       2011  \\\n",
       "transect_id                                                            \n",
       "BOX_051_151_15  700.6640  712.41740  708.45123  740.33240  680.42510   \n",
       "BOX_051_151_18  763.1057  759.72600  766.23150  770.77130  798.26830   \n",
       "BOX_051_151_21  825.8698  820.51720  820.68680  842.18097  850.45460   \n",
       "BOX_051_151_30  823.7820  823.15674  823.65790  821.31860  818.85803   \n",
       "BOX_051_151_32  301.1231  313.63553  313.09814  312.90347  306.18658   \n",
       "\n",
       "                     2012       2013       2014       2015       2016  \n",
       "transect_id                                                            \n",
       "BOX_051_151_15  758.35150  754.49695  763.04297  743.29680  779.41570  \n",
       "BOX_051_151_18  797.99615  803.90950  797.90780  798.18830  803.68256  \n",
       "BOX_051_151_21  775.96700  883.04240  867.92426  877.37415  874.50244  \n",
       "BOX_051_151_30  817.31220  822.92970  818.73350  822.18480  818.73480  \n",
       "BOX_051_151_32  294.18326  297.23654  302.88650  323.85840  304.36823  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = tf.set_index('transect_id')\n",
    "tf = tf.dropna(thresh=33)\n",
    "print(f\"Transects included in dataset: {tf.shape[0]}; timesteps: {tf.shape[1]}\")\n",
    "tf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = tf.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = pd.read_csv(\"/media/storage/data/shorelines/sites-gluonts-prepared-37k.csv\")\n",
    "sites = sites.loc[sites['transect_id'].isin(tf.index)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import ward, fcluster\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "Z = ward(pdist(sites[['Intersect_lon', 'Intersect_lat']].values))\n",
    "sites['fcluster'] = fcluster(Z, t=0.1, criterion='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PUgQzQFNSwJd"
   },
   "outputs": [],
   "source": [
    "metadata = {\n",
    "    'num_series': len(tf),\n",
    "    'num_steps': len(tf.columns),\n",
    "    'prediction_length': 7,\n",
    "    'freq': \"AS\",\n",
    "    'start': [pd.Timestamp(\"01-01-1984\", freq='AS') for _ in range(len(tf))],\n",
    "    'item_id': tf.index.values,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wgXS2CelSwSm"
   },
   "outputs": [],
   "source": [
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.dataset.field_names import FieldName\n",
    "\n",
    "\n",
    "def get_gluon_ds():\n",
    "\n",
    "    train_ds = ListDataset(\n",
    "        [\n",
    "         {\n",
    "             FieldName.TARGET: target,\n",
    "             FieldName.START: start,\n",
    "             FieldName.ITEM_ID: item_id,\n",
    "             FieldName.FEAT_STATIC_CAT: [fclust, dbclust],\n",
    "             FieldName.FEAT_STATIC_REAL: [fsr]\n",
    "          }\n",
    "\n",
    "         for (target, start, item_id, fclust, dbclust, fsr) in zip(tf.values[:, :-metadata['prediction_length']],\n",
    "                                            metadata['start'], \n",
    "                                            metadata['item_id'],\n",
    "                                            sites['fcluster'].values,\n",
    "                                            sites['dbscan_cluster'].values,\n",
    "                                            sites['changerate_unc'].values)\n",
    "        ], freq=metadata['freq'])\n",
    "\n",
    "    test_ds = ListDataset(\n",
    "        [\n",
    "         {\n",
    "             FieldName.TARGET: target,\n",
    "             FieldName.START: start,\n",
    "             FieldName.ITEM_ID: item_id,\n",
    "             FieldName.FEAT_STATIC_CAT: [fclust, dbclust],\n",
    "             FieldName.FEAT_STATIC_REAL: [fsr]\n",
    "          }\n",
    "\n",
    "         for (target, start, item_id, fclust, dbclust, fsr) in zip(tf.values,\n",
    "                                            metadata['start'], \n",
    "                                            metadata['item_id'],\n",
    "                                            sites['fcluster'].values,\n",
    "                                            sites['dbscan_cluster'].values,\n",
    "                                            sites['changerate_unc'].values)\n",
    "        ], freq=metadata['freq'])\n",
    "          \n",
    "    return train_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, test_ds = get_gluon_ds()\n",
    "\n",
    "train_it = iter(train_ds)\n",
    "test_it = iter(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.model.deepar import DeepAREstimator\n",
    "from gluonts.model.seq2seq import MQCNNEstimator\n",
    "from gluonts.model.simple_feedforward import SimpleFeedForwardEstimator\n",
    "from gluonts.model.deepstate import DeepStateEstimator\n",
    "\n",
    "from gluonts.transform import (\n",
    "    AddAgeFeature,\n",
    "    AddObservedValuesIndicator,\n",
    "    Chain,\n",
    "    ExpectedNumInstanceSampler,\n",
    "    InstanceSplitter,\n",
    "    SetFieldIfNotPresent,\n",
    ")\n",
    "\n",
    "class MySimpleFeedForward(SimpleFeedForwardEstimator):\n",
    "\n",
    "    def create_transformation(self):\n",
    "        return Chain(\n",
    "            [\n",
    "                AddObservedValuesIndicator(\n",
    "                    target_field=FieldName.TARGET,\n",
    "                    output_field=FieldName.OBSERVED_VALUES,\n",
    "                ),\n",
    "                AddAgeFeature(\n",
    "                    target_field=FieldName.TARGET,\n",
    "                    output_field=FieldName.FEAT_AGE,\n",
    "                    pred_length=self.prediction_length,\n",
    "                    log_scale=True,\n",
    "                ),\n",
    "                InstanceSplitter(\n",
    "                    target_field=FieldName.TARGET,\n",
    "                    is_pad_field=FieldName.IS_PAD,\n",
    "                    start_field=FieldName.START,\n",
    "                    forecast_start_field=FieldName.FORECAST_START,\n",
    "                    train_sampler=ExpectedNumInstanceSampler(num_instances=1),\n",
    "                    past_length=self.context_length,\n",
    "                    future_length=self.prediction_length,\n",
    "                    time_series_fields=[\n",
    "                        FieldName.FEAT_AGE,\n",
    "                        FieldName.OBSERVED_VALUES,\n",
    "                    ],\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    \n",
    "class MyMQCNN(MQCNNEstimator):\n",
    "\n",
    "    def create_transformation(self):\n",
    "        return Chain(\n",
    "            [\n",
    "                AddObservedValuesIndicator(\n",
    "                    target_field=FieldName.TARGET,\n",
    "                    output_field=FieldName.OBSERVED_VALUES,\n",
    "                ),\n",
    "                AddAgeFeature(\n",
    "                    target_field=FieldName.TARGET,\n",
    "                    output_field=FieldName.FEAT_AGE,\n",
    "                    pred_length=self.prediction_length,\n",
    "                    log_scale=True,\n",
    "                ),\n",
    "                InstanceSplitter(\n",
    "                    target_field=FieldName.TARGET,\n",
    "                    is_pad_field=FieldName.IS_PAD,\n",
    "                    start_field=FieldName.START,\n",
    "                    forecast_start_field=FieldName.FORECAST_START,\n",
    "                    train_sampler=ExpectedNumInstanceSampler(num_instances=1),\n",
    "                    past_length=self.context_length,\n",
    "                    future_length=self.prediction_length,\n",
    "                    time_series_fields=[\n",
    "                        FieldName.FEAT_AGE,\n",
    "                        FieldName.OBSERVED_VALUES,\n",
    "                    ],\n",
    "                ),\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "uYELgYifrOxh",
    "outputId": "8274631a-42fc-4b4d-e022-b7eb97016106",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[946, 931]\n",
      "evaluating gluonts.model.seq2seq._mq_dnn_estimator.MQCNNEstimator(context_length=None, freq=\"AS\", mlp_final_dim=20, mlp_hidden_dimension_seq=[], prediction_length=7, quantiles=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], trainer=gluonts.trainer._base.Trainer(batch_size=32, clip_gradient=10.0, ctx=None, epochs=10, hybridize=True, init=\"xavier\", learning_rate=0.001, learning_rate_decay_factor=0.5, minimum_learning_rate=5e-05, num_batches_per_epoch=300, patience=10, weight_decay=1e-08))\n",
      "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:07<00:00, 41.06it/s, epoch=1/10, avg_epoch_loss=13.5]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:07<00:00, 39.85it/s, epoch=2/10, avg_epoch_loss=1.53]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:07<00:00, 42.24it/s, epoch=3/10, avg_epoch_loss=1.52]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:07<00:00, 41.75it/s, epoch=4/10, avg_epoch_loss=1.5]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:07<00:00, 42.44it/s, epoch=5/10, avg_epoch_loss=1.51]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:07<00:00, 42.69it/s, epoch=6/10, avg_epoch_loss=1.49]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:07<00:00, 42.08it/s, epoch=7/10, avg_epoch_loss=1.49]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:07<00:00, 38.20it/s, epoch=8/10, avg_epoch_loss=1.48]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:07<00:00, 39.24it/s, epoch=9/10, avg_epoch_loss=1.47]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:08<00:00, 37.01it/s, epoch=10/10, avg_epoch_loss=1.48]\n",
      "Running evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:01<00:00, 743.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 157: MAPE 0.07408936366202057\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "from gluonts.distribution.piecewise_linear import PiecewiseLinearOutput\n",
    "from gluonts.evaluation import Evaluator\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.model.deepar import DeepAREstimator\n",
    "from gluonts.model.seq2seq import MQCNNEstimator\n",
    "from gluonts.model.simple_feedforward import SimpleFeedForwardEstimator\n",
    "from gluonts.model.deepstate import DeepStateEstimator\n",
    "from gluonts.trainer import Trainer\n",
    "\n",
    "from shorelineforecasting.utils.configs import get_predictor_id\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "num_batches_per_epoch = 300\n",
    "cardinality = [len(sites['fcluster'].unique()), len(sites['dbscan_cluster'].unique())]\n",
    "print(cardinality)\n",
    "\n",
    "estimators = [\n",
    "#     partial(\n",
    "#         SimpleFeedForwardEstimator,\n",
    "#         freq=metadata[\"freq\"],\n",
    "#         trainer=Trainer(\n",
    "#             epochs=epochs, num_batches_per_epoch=num_batches_per_epoch\n",
    "#         ),\n",
    "#     ),\n",
    "#     partial(\n",
    "#         MySimpleFeedForward,\n",
    "#         freq=metadata[\"freq\"],\n",
    "#         trainer=Trainer(\n",
    "#             epochs=epochs, num_batches_per_epoch=num_batches_per_epoch\n",
    "#         ),\n",
    "#     ),  \n",
    "    \n",
    "    \n",
    "#     partial(\n",
    "#         DeepAREstimator,\n",
    "#         freq=\"12M\",\n",
    "#         use_feat_static_real=True,\n",
    "#         use_feat_static_cat=True,\n",
    "#         cardinality=cardinality,\n",
    "#         time_features=[],\n",
    "#         trainer=Trainer(\n",
    "#             epochs=epochs,\n",
    "#             num_batches_per_epoch=num_batches_per_epoch,\n",
    "#             batch_size=batch_size\n",
    "#         ),\n",
    "#     ),\n",
    "    \n",
    "    \n",
    "#     partial(\n",
    "#         DeepAREstimator,\n",
    "#         freq=\"12M\",\n",
    "#         use_feat_static_real=True,\n",
    "#         use_feat_static_cat=True,\n",
    "#         cardinality=cardinality,\n",
    "#         distr_output=PiecewiseLinearOutput(8),\n",
    "#         trainer=Trainer(\n",
    "#             epochs=epochs, num_batches_per_epoch=num_batches_per_epoch\n",
    "#         ),\n",
    "#     ),\n",
    "#     partial(\n",
    "#         DeepStateEstimator,\n",
    "#         freq=metadata[\"freq\"],\n",
    "#         cardinality=cardinality,\n",
    "#         trainer=Trainer(\n",
    "#             epochs=epochs, num_batches_per_epoch=num_batches_per_epoch\n",
    "#         ),\n",
    "#     ),\n",
    "    partial(\n",
    "        MQCNNEstimator,\n",
    "        freq=metadata[\"freq\"],\n",
    "        trainer=Trainer(\n",
    "            epochs=epochs, num_batches_per_epoch=num_batches_per_epoch\n",
    "        ),\n",
    "    ),\n",
    "#     partial(\n",
    "#         MyMQCNN,\n",
    "#         freq=metadata[\"freq\"],\n",
    "#         trainer=Trainer(\n",
    "#             epochs=epochs, num_batches_per_epoch=num_batches_per_epoch\n",
    "#         ),\n",
    "#     ),\n",
    "]\n",
    "\n",
    "\n",
    "def evaluate(estimator):\n",
    "    estimator = estimator(\n",
    "        prediction_length=metadata['prediction_length'],\n",
    "#         context_length=2*metadata['prediction_length'],\n",
    "    )\n",
    "\n",
    "    print(f\"evaluating {estimator}\")\n",
    "\n",
    "    predictor = estimator.train(train_ds)\n",
    "\n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "        test_ds, predictor=predictor, num_samples=100\n",
    "    )\n",
    "\n",
    "    agg_metrics, item_metrics = Evaluator()(\n",
    "        ts_it, forecast_it, num_series=len(test_ds)\n",
    "    )\n",
    "    \n",
    "    item_metrics[\"prediction_length\"] = metadata['prediction_length']\n",
    "#     item_metrics[\"context_length\"] = metadata['num_steps'] - metadata['prediction_length']\n",
    "    item_metrics[\"predictor\"] = type(estimator).__name__\n",
    "    item_metrics[\"predictor_id\"] = get_predictor_id()\n",
    "    agg_metrics[\"predictor\"] = type(estimator).__name__\n",
    "    \n",
    "    return item_metrics\n",
    "\n",
    "\n",
    "metrics = []\n",
    "for prediction_length in np.arange(7, 8, 1):\n",
    "    metadata['prediction_length'] = prediction_length\n",
    "    train_ds, test_ds = get_gluon_ds() # update according to metadata\n",
    "    for estimator in estimators:\n",
    "        # catch exceptions that are happening during training to avoid failing the whole evaluation\n",
    "        try:\n",
    "            metrics.append(evaluate(estimator))\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "#     pd.concat(metrics).to_csv(\"/media/storage/data/shorelines/dl-metrics-9.csv\", index=False, header=True)\n",
    "\n",
    "for gr, frame in pd.concat(metrics).groupby('predictor_id'):\n",
    "    print(f\"Group {gr}: MAPE {frame['MAPE'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>abs_error</th>\n",
       "      <th>abs_target_sum</th>\n",
       "      <th>abs_target_mean</th>\n",
       "      <th>seasonal_error</th>\n",
       "      <th>MASE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>sMAPE</th>\n",
       "      <th>OWA</th>\n",
       "      <th>MSIS</th>\n",
       "      <th>...</th>\n",
       "      <th>Coverage[0.5]</th>\n",
       "      <th>QuantileLoss[0.6]</th>\n",
       "      <th>Coverage[0.6]</th>\n",
       "      <th>QuantileLoss[0.7]</th>\n",
       "      <th>Coverage[0.7]</th>\n",
       "      <th>QuantileLoss[0.8]</th>\n",
       "      <th>Coverage[0.8]</th>\n",
       "      <th>QuantileLoss[0.9]</th>\n",
       "      <th>Coverage[0.9]</th>\n",
       "      <th>prediction_length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictor_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>19001.444272</td>\n",
       "      <td>831.351187</td>\n",
       "      <td>5148.241266</td>\n",
       "      <td>735.463038</td>\n",
       "      <td>13.435316</td>\n",
       "      <td>12.828042</td>\n",
       "      <td>0.219557</td>\n",
       "      <td>0.151702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.170413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975895</td>\n",
       "      <td>740.274627</td>\n",
       "      <td>0.980402</td>\n",
       "      <td>626.318318</td>\n",
       "      <td>0.983890</td>\n",
       "      <td>481.371367</td>\n",
       "      <td>0.987193</td>\n",
       "      <td>298.975908</td>\n",
       "      <td>0.990727</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>3672.157100</td>\n",
       "      <td>198.530911</td>\n",
       "      <td>5148.241266</td>\n",
       "      <td>735.463038</td>\n",
       "      <td>13.435316</td>\n",
       "      <td>2.462395</td>\n",
       "      <td>0.071973</td>\n",
       "      <td>0.044381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.522021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.755698</td>\n",
       "      <td>199.604428</td>\n",
       "      <td>0.806992</td>\n",
       "      <td>193.042139</td>\n",
       "      <td>0.851211</td>\n",
       "      <td>175.566079</td>\n",
       "      <td>0.888412</td>\n",
       "      <td>142.054784</td>\n",
       "      <td>0.926745</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>3748.577692</td>\n",
       "      <td>206.461076</td>\n",
       "      <td>5148.241266</td>\n",
       "      <td>735.463038</td>\n",
       "      <td>13.435316</td>\n",
       "      <td>2.558043</td>\n",
       "      <td>0.070498</td>\n",
       "      <td>0.045473</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.635919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203074</td>\n",
       "      <td>214.343514</td>\n",
       "      <td>0.257013</td>\n",
       "      <td>212.508028</td>\n",
       "      <td>0.333213</td>\n",
       "      <td>203.000373</td>\n",
       "      <td>0.430100</td>\n",
       "      <td>165.960534</td>\n",
       "      <td>0.647417</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>NaN</td>\n",
       "      <td>222.111760</td>\n",
       "      <td>5148.241266</td>\n",
       "      <td>735.463038</td>\n",
       "      <td>13.435316</td>\n",
       "      <td>3.171050</td>\n",
       "      <td>0.065219</td>\n",
       "      <td>0.047424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.498062</td>\n",
       "      <td>183.263779</td>\n",
       "      <td>0.602601</td>\n",
       "      <td>149.402961</td>\n",
       "      <td>0.606986</td>\n",
       "      <td>160.980377</td>\n",
       "      <td>0.703084</td>\n",
       "      <td>140.450943</td>\n",
       "      <td>0.726662</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       MSE   abs_error  abs_target_sum  abs_target_mean  \\\n",
       "predictor_id                                                              \n",
       "147           19001.444272  831.351187     5148.241266       735.463038   \n",
       "148            3672.157100  198.530911     5148.241266       735.463038   \n",
       "149            3748.577692  206.461076     5148.241266       735.463038   \n",
       "150                    NaN  222.111760     5148.241266       735.463038   \n",
       "\n",
       "              seasonal_error       MASE      MAPE     sMAPE  OWA       MSIS  \\\n",
       "predictor_id                                                                  \n",
       "147                13.435316  12.828042  0.219557  0.151702  NaN  65.170413   \n",
       "148                13.435316   2.462395  0.071973  0.044381  NaN  29.522021   \n",
       "149                13.435316   2.558043  0.070498  0.045473  NaN  28.635919   \n",
       "150                13.435316   3.171050  0.065219  0.047424  NaN        NaN   \n",
       "\n",
       "              ...  Coverage[0.5]  QuantileLoss[0.6]  Coverage[0.6]  \\\n",
       "predictor_id  ...                                                    \n",
       "147           ...       0.975895         740.274627       0.980402   \n",
       "148           ...       0.755698         199.604428       0.806992   \n",
       "149           ...       0.203074         214.343514       0.257013   \n",
       "150           ...       0.498062         183.263779       0.602601   \n",
       "\n",
       "              QuantileLoss[0.7]  Coverage[0.7]  QuantileLoss[0.8]  \\\n",
       "predictor_id                                                        \n",
       "147                  626.318318       0.983890         481.371367   \n",
       "148                  193.042139       0.851211         175.566079   \n",
       "149                  212.508028       0.333213         203.000373   \n",
       "150                  149.402961       0.606986         160.980377   \n",
       "\n",
       "              Coverage[0.8]  QuantileLoss[0.9]  Coverage[0.9]  \\\n",
       "predictor_id                                                    \n",
       "147                0.987193         298.975908       0.990727   \n",
       "148                0.888412         142.054784       0.926745   \n",
       "149                0.430100         165.960534       0.647417   \n",
       "150                0.703084         140.450943       0.726662   \n",
       "\n",
       "              prediction_length  \n",
       "predictor_id                     \n",
       "147                           7  \n",
       "148                           7  \n",
       "149                           7  \n",
       "150                           7  \n",
       "\n",
       "[4 rows x 29 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(metrics).groupby('predictor_id').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>abs_error</th>\n",
       "      <th>abs_target_sum</th>\n",
       "      <th>abs_target_mean</th>\n",
       "      <th>seasonal_error</th>\n",
       "      <th>MASE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>sMAPE</th>\n",
       "      <th>OWA</th>\n",
       "      <th>MSIS</th>\n",
       "      <th>...</th>\n",
       "      <th>Coverage[0.5]</th>\n",
       "      <th>QuantileLoss[0.6]</th>\n",
       "      <th>Coverage[0.6]</th>\n",
       "      <th>QuantileLoss[0.7]</th>\n",
       "      <th>Coverage[0.7]</th>\n",
       "      <th>QuantileLoss[0.8]</th>\n",
       "      <th>Coverage[0.8]</th>\n",
       "      <th>QuantileLoss[0.9]</th>\n",
       "      <th>Coverage[0.9]</th>\n",
       "      <th>prediction_length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictor_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1871.505826</td>\n",
       "      <td>139.265537</td>\n",
       "      <td>5148.241266</td>\n",
       "      <td>735.463038</td>\n",
       "      <td>13.435316</td>\n",
       "      <td>1.772990</td>\n",
       "      <td>0.058572</td>\n",
       "      <td>0.031126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.283065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727820</td>\n",
       "      <td>139.388790</td>\n",
       "      <td>0.791548</td>\n",
       "      <td>133.423694</td>\n",
       "      <td>0.844836</td>\n",
       "      <td>118.476903</td>\n",
       "      <td>0.888304</td>\n",
       "      <td>90.717742</td>\n",
       "      <td>0.931045</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2150.574743</td>\n",
       "      <td>145.686622</td>\n",
       "      <td>5148.241266</td>\n",
       "      <td>735.463038</td>\n",
       "      <td>13.435316</td>\n",
       "      <td>1.812748</td>\n",
       "      <td>0.049397</td>\n",
       "      <td>0.032730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.232659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.719101</td>\n",
       "      <td>144.879474</td>\n",
       "      <td>0.773190</td>\n",
       "      <td>138.559651</td>\n",
       "      <td>0.822817</td>\n",
       "      <td>124.510421</td>\n",
       "      <td>0.867517</td>\n",
       "      <td>99.161096</td>\n",
       "      <td>0.914992</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2103.366009</td>\n",
       "      <td>141.338182</td>\n",
       "      <td>5148.241266</td>\n",
       "      <td>735.463038</td>\n",
       "      <td>13.435316</td>\n",
       "      <td>1.746742</td>\n",
       "      <td>0.047908</td>\n",
       "      <td>0.031775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.095838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.713959</td>\n",
       "      <td>141.211175</td>\n",
       "      <td>0.769121</td>\n",
       "      <td>134.827595</td>\n",
       "      <td>0.814445</td>\n",
       "      <td>120.908900</td>\n",
       "      <td>0.853624</td>\n",
       "      <td>98.519893</td>\n",
       "      <td>0.909869</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>NaN</td>\n",
       "      <td>117.713779</td>\n",
       "      <td>5148.241266</td>\n",
       "      <td>735.463038</td>\n",
       "      <td>13.435316</td>\n",
       "      <td>1.412177</td>\n",
       "      <td>0.041971</td>\n",
       "      <td>0.027286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.352333</td>\n",
       "      <td>114.117820</td>\n",
       "      <td>0.565558</td>\n",
       "      <td>111.784716</td>\n",
       "      <td>0.675868</td>\n",
       "      <td>103.464447</td>\n",
       "      <td>0.750101</td>\n",
       "      <td>83.767415</td>\n",
       "      <td>0.861866</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      MSE   abs_error  abs_target_sum  abs_target_mean  \\\n",
       "predictor_id                                                             \n",
       "143           1871.505826  139.265537     5148.241266       735.463038   \n",
       "144           2150.574743  145.686622     5148.241266       735.463038   \n",
       "145           2103.366009  141.338182     5148.241266       735.463038   \n",
       "146                   NaN  117.713779     5148.241266       735.463038   \n",
       "\n",
       "              seasonal_error      MASE      MAPE     sMAPE  OWA       MSIS  \\\n",
       "predictor_id                                                                 \n",
       "143                13.435316  1.772990  0.058572  0.031126  NaN  22.283065   \n",
       "144                13.435316  1.812748  0.049397  0.032730  NaN  22.232659   \n",
       "145                13.435316  1.746742  0.047908  0.031775  NaN  22.095838   \n",
       "146                13.435316  1.412177  0.041971  0.027286  NaN        NaN   \n",
       "\n",
       "              ...  Coverage[0.5]  QuantileLoss[0.6]  Coverage[0.6]  \\\n",
       "predictor_id  ...                                                    \n",
       "143           ...       0.727820         139.388790       0.791548   \n",
       "144           ...       0.719101         144.879474       0.773190   \n",
       "145           ...       0.713959         141.211175       0.769121   \n",
       "146           ...       0.352333         114.117820       0.565558   \n",
       "\n",
       "              QuantileLoss[0.7]  Coverage[0.7]  QuantileLoss[0.8]  \\\n",
       "predictor_id                                                        \n",
       "143                  133.423694       0.844836         118.476903   \n",
       "144                  138.559651       0.822817         124.510421   \n",
       "145                  134.827595       0.814445         120.908900   \n",
       "146                  111.784716       0.675868         103.464447   \n",
       "\n",
       "              Coverage[0.8]  QuantileLoss[0.9]  Coverage[0.9]  \\\n",
       "predictor_id                                                    \n",
       "143                0.888304          90.717742       0.931045   \n",
       "144                0.867517          99.161096       0.914992   \n",
       "145                0.853624          98.519893       0.909869   \n",
       "146                0.750101          83.767415       0.861866   \n",
       "\n",
       "              prediction_length  \n",
       "predictor_id                     \n",
       "143                           7  \n",
       "144                           7  \n",
       "145                           7  \n",
       "146                           7  \n",
       "\n",
       "[4 rows x 29 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(metrics).groupby('predictor_id').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05697571455006599\n",
      "0.05013267189624887\n",
      "0.04456121455097609\n",
      "0.06555314856955873\n"
     ]
    }
   ],
   "source": [
    "for gr, frame in pd.concat(metrics).groupby('predictor_id'):\n",
    "    print(frame['MAPE'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0570972067798468\n",
      "0.045237669125545554\n",
      "0.05134579319014857\n",
      "0.04160705504096912\n"
     ]
    }
   ],
   "source": [
    "for gr, frame in pd.read_csv(\"/media/storage/data/shorelines/dl-metrics-1.csv\").groupby('predictor_id'):\n",
    "    print(frame['MAPE'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(7, 8, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_1 = pd.read_csv(\"/media/storage/data/shorelines/dl-metrics-robustness.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([metrics_1, metrics_2]).to_csv(\"/media/storage/data/shorelines/dl-metrics-robustness.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"/media/storage/data/shorelines/dl-metrics-robustness.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_2 = pd.concat(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAPE</th>\n",
       "      <th>sMAPE</th>\n",
       "      <th>prediction_length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictor_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.105766</td>\n",
       "      <td>0.067504</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.067642</td>\n",
       "      <td>0.038131</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.060585</td>\n",
       "      <td>0.034388</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.038419</td>\n",
       "      <td>0.028056</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.222379</td>\n",
       "      <td>0.155472</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.072850</td>\n",
       "      <td>0.038663</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.064954</td>\n",
       "      <td>0.048274</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1.223889</td>\n",
       "      <td>0.716871</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.811598</td>\n",
       "      <td>0.481986</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.060478</td>\n",
       "      <td>0.037674</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.059044</td>\n",
       "      <td>0.037528</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>1.609978</td>\n",
       "      <td>1.984642</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  MAPE     sMAPE  prediction_length\n",
       "predictor_id                                       \n",
       "121           0.105766  0.067504                  5\n",
       "122           0.067642  0.038131                  5\n",
       "123           0.060585  0.034388                  5\n",
       "124           0.038419  0.028056                  5\n",
       "125           0.222379  0.155472                  9\n",
       "126           0.072850  0.038663                  9\n",
       "127           0.064954  0.048274                  9\n",
       "128           1.223889  0.716871                  9\n",
       "129           0.811598  0.481986                 13\n",
       "130           0.060478  0.037674                 13\n",
       "131           0.059044  0.037528                 13\n",
       "132           1.609978  1.984642                 13"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(metrics).groupby('predictor_id').mean()[['MAPE','sMAPE', 'prediction_length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(16, 17, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  9, 13, 17, 21, 25])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(5, 28, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17, 21, 25])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(17, 28, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.dataset.util import to_pandas\n",
    "\n",
    "\n",
    "train_entry = next(iter(train_ds))\n",
    "train_entry.keys()\n",
    "\n",
    "test_entry = next(iter(test_ds))\n",
    "test_entry.keys()\n",
    "\n",
    "test_series = to_pandas(test_entry)\n",
    "train_series = to_pandas(train_entry)\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, sharex=True, sharey=True, figsize=(10, 7))\n",
    "\n",
    "train_series.plot(ax=ax[0])\n",
    "ax[0].grid(which=\"both\")\n",
    "ax[0].legend([\"train series\"], loc=\"upper left\")\n",
    "\n",
    "test_series.plot(ax=ax[1])\n",
    "ax[1].axvline(train_series.index[-1], color='r') # end of train dataset\n",
    "ax[1].grid(which=\"both\")\n",
    "ax[1].legend([\"test series\", \"end of train series\"], loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_metrics_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_metrics_1 = pd.concat(item_metrics_list)\n",
    "# item_metrics_2 = pd.concat(item_metrics_list)\n",
    "item_metrics_5 = pd.concat(item_metrics_list)\n",
    "# item_metrics_5.to_pickle('/media/storage/data/shorelines/dl-metrics-2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for estimator_id in item_metrics_5[\"estimator_id\"].unique():\n",
    "    tmp = item_metrics_5.loc[item_metrics_5[\"estimator_id\"]==estimator_id]\n",
    "    for c in list(tmp.select_dtypes(include=[np.float])):\n",
    "        print(f\"{c}: {tmp[c].mean()}\")\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_pickle(\"/media/storage/data/shorelines/lr-metrics.pkl\")['mape'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for estimator_id in item_metrics_2[\"estimator_id\"].unique():\n",
    "    tmp = item_metrics_1.loc[item_metrics_1[\"estimator_id\"]==estimator_id]\n",
    "    for c in list(tmp.select_dtypes(include=[np.float])):\n",
    "        print(f\"{c}: {tmp[c].mean()}\")\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for estimator_id in item_metrics_1[\"estimator_id\"].unique():\n",
    "    tmp = item_metrics_1.loc[item_metrics_1[\"estimator_id\"]==estimator_id]\n",
    "    for c in list(tmp.select_dtypes(include=[np.float])):\n",
    "        print(f\"{c}: {tmp[c].mean()}\")\n",
    "    print(\"-\"*100)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for estimator in item_metrics[\"estimator\"].unique():\n",
    "    metrics = item_metrics.loc[item_metrics[\"estimator\"]==estimator]\n",
    "    print(\"-\"*100)\n",
    "    print(estimator)\n",
    "    print(\"-\"*100)\n",
    "    for i in list(metrics.select_dtypes(include=[np.float])):\n",
    "        print(f\"{i}: {metrics[i].mean()}\")\n",
    "\n",
    "# item_metrics.loc[item_metrics[\"estimator\"]==]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_metrics.to_pickle(\"/media/storage/data/shorelines/metrics-gluonts.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "jMFx3tuWzLtB",
    "outputId": "e0c5d17a-3413-4a93-b21f-dc039a7a90dd"
   },
   "outputs": [],
   "source": [
    "eval_item_dict_list[0][\"item_metrics\"]['MAPE'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "7vAxE20_0Q-a",
    "outputId": "4bea48eb-3238-4e3c-ddec-2f80459ec517"
   },
   "outputs": [],
   "source": [
    "for i in eval_item_dict_list:\n",
    "  metrics = i[\"item_metrics\"]\n",
    "  print(metrics[\"MAPE\"].mean())\n",
    "  print(max(metrics[\"MAPE\"]))\n",
    "  print(min(metrics[\"MAPE\"]))\n",
    "  print(\"---\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zDI98dk3f8OL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 700
    },
    "id": "TTbyacr1xSdE",
    "outputId": "d72fc2eb-cbb6-484b-c6d5-cd42474fc4a3"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "for i in eval_item_dict_list:\n",
    "  metrics = i[\"item_metrics\"]\n",
    "  metrics[\"MSE\"].plot(kind='hist')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "bMk64uS6rOsy",
    "outputId": "0660763a-f2ad-464c-dffe-596fcc859600"
   },
   "outputs": [],
   "source": [
    "ff# all_metrics = pd.concat(item_metrics_list)\n",
    "all_metrics['MAPE'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBzgVWR-iYPJ"
   },
   "source": [
    "## Sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0OHKMiIorOpq"
   },
   "outputs": [],
   "source": [
    "from gluonts.dataset.artificial import ConstantDataset\n",
    "\n",
    "\n",
    "metadata = {'num_series': 1000, \n",
    "            'num_steps': 33, \n",
    "            'prediction_length': 7,\n",
    "            'freq': '365D',   # not 1Y for DeepAR freq requirements\n",
    "            'start': [pd.Timestamp(\"01-01-1984\", freq='365D') for _ in range(len(tf))]\n",
    "            }\n",
    "\n",
    "ds_generator = ConstantDataset(num_timeseries = metadata['num_series'],\n",
    "                              num_steps = metadata['num_steps'],\n",
    "                              freq = metadata['freq'],\n",
    "                              start = '1984-01-01 00:00:00')\n",
    "\n",
    "constant_ds = ds_generator.generate()\n",
    "train_ds = constant_ds.train\n",
    "test_ds = constant_ds.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "d_xjv6CUYZvF",
    "outputId": "62f2f8b5-1d91-46e2-cdef-1d86f7b61499"
   },
   "outputs": [],
   "source": [
    "# from gluonts.model.simple_feedforward import SimpleFeedForwardEstimator\n",
    "# from gluonts.trainer import Trainer\n",
    "\n",
    "# estimator = SimpleFeedForwardEstimator(\n",
    "#     num_hidden_dimensions=[10],\n",
    "#     prediction_length=metadata['prediction_length'],\n",
    "#     context_length=metadata['prediction_length'] * 2,\n",
    "#     freq=metadata['freq'],\n",
    "#     trainer=Trainer(ctx=\"cpu\", \n",
    "#                     epochs=20, \n",
    "#                     learning_rate=1e-3, \n",
    "#                     hybridize=False, \n",
    "#                     num_batches_per_epoch=100\n",
    "#                    )\n",
    "# )\n",
    "\n",
    "# predictor = estimator.train(train_ds)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from gluonts.model.deepar import DeepAREstimator\n",
    "from gluonts.distribution.neg_binomial import NegativeBinomialOutput\n",
    "from gluonts.trainer import Trainer\n",
    "\n",
    "estimator = DeepAREstimator(\n",
    "    prediction_length=metadata['prediction_length'],\n",
    "    freq=\"M\",\n",
    "    distr_output = NegativeBinomialOutput(),\n",
    "    use_feat_dynamic_real=False,\n",
    "    use_feat_static_cat=False,\n",
    "    # cardinality=stat_cat_cardinalities,\n",
    "    trainer=Trainer(\n",
    "        learning_rate=1e-3,\n",
    "        epochs=10,\n",
    "        num_batches_per_epoch=50,\n",
    "        batch_size=32\n",
    "    )\n",
    ")\n",
    "\n",
    "predictor = estimator.train(train_ds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "DR2c7U3hYZ2n",
    "outputId": "fd6d9087-39bf-44bb-ab7c-5590c1c50cad"
   },
   "outputs": [],
   "source": [
    "# save the trained model in tmp/\n",
    "from pathlib import Path\n",
    "predictor.serialize(Path(\"/tmp/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0LVqE50bYZ-D"
   },
   "outputs": [],
   "source": [
    "# loads it back\n",
    "from gluonts.model.predictor import Predictor\n",
    "predictor_deserialized = Predictor.deserialize(Path(\"/tmp/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "riQWhFpQebyd",
    "outputId": "b5770804-ed80-4a26-d7a6-3ec481f1e225"
   },
   "outputs": [],
   "source": [
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "\n",
    "forecast_it, ts_it = make_evaluation_predictions(\n",
    "    dataset=test_ds,  # test dataset\n",
    "    predictor=predictor,  # predictor\n",
    "    num_samples=100,  # number of sample paths we want for evaluation\n",
    ")\n",
    "\n",
    "forecasts = list(forecast_it)\n",
    "tss = list(ts_it)\n",
    "\n",
    "# first entry of the time series list\n",
    "ts_entry = tss[0]\n",
    "forecast_entry =  forecasts[0]\n",
    "test_ds_entry = next(iter(test_ds))\n",
    "\n",
    "# first 5 values of the time series (convert from pandas to numpy)\n",
    "np.array(ts_entry[:5]).reshape(-1,)\n",
    "\n",
    "# first 5 values\n",
    "test_ds_entry['target'][:5]\n",
    "\n",
    "print(f\"Number of sample paths: {forecast_entry.num_samples}\")\n",
    "print(f\"Dimension of samples: {forecast_entry.samples.shape}\")\n",
    "print(f\"Start date of the forecast window: {forecast_entry.start_date}\")\n",
    "print(f\"Frequency of the time series: {forecast_entry.freq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "OBY-26Vcec0m",
    "outputId": "9c3b1f8f-2c2a-4531-cb7b-16efdabec4d1"
   },
   "outputs": [],
   "source": [
    "print(f\"Mean of the future window:\\n {forecast_entry.mean}\")\n",
    "print(f\"0.5-quantile (median) of the future window:\\n {forecast_entry.quantile(0.5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9x9SJbWpehPL",
    "outputId": "3f394c42-874c-483f-abc0-a6684026b8e3"
   },
   "outputs": [],
   "source": [
    "def plot_prob_forecasts(ts_entry, forecast_entry):\n",
    "    plot_length = 100 \n",
    "    prediction_intervals = (50.0, 90.0)\n",
    "    legend = [\"observations\", \"median prediction\"] + [f\"{k}% prediction interval\" for k in prediction_intervals][::-1]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 7))\n",
    "    ts_entry[-plot_length:].plot(ax=ax)  # plot the time series\n",
    "    forecast_entry.plot(prediction_intervals=prediction_intervals, color='g')\n",
    "    plt.grid(which=\"both\")\n",
    "    plt.legend(legend, loc=\"upper left\")\n",
    "    plt.show()\n",
    "\n",
    "for forecast_entry, ts_entry in zip(forecasts[:30], tss[:30]):\n",
    "  plot_prob_forecasts(ts_entry, forecast_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "S-Ei6826k5X0",
    "outputId": "b1b69344-abff-490a-fc26-211c6afa25c6"
   },
   "outputs": [],
   "source": [
    "print(len(tss))\n",
    "print(len(forecasts))\n",
    "print(len(test_ds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "id": "3up-4z43lU7_",
    "outputId": "0d5ab9a8-d055-4554-c681-9da76b75b5e4"
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(4):\n",
    "    count+=1\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "QNfoMrWPfr6n",
    "outputId": "fcee96fa-1503-43ef-82af-24d6167eadd3"
   },
   "outputs": [],
   "source": [
    "from gluonts.evaluation import Evaluator\n",
    "evaluator = Evaluator(quantiles=[0.1, 0.5, 0.9])\n",
    "agg_metrics, item_metrics = evaluator(iter(tss[:10000]), iter(forecasts[:10000]), num_series=10000)\n",
    "print(json.dumps(agg_metrics, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "mVN-NHvGfvEW",
    "outputId": "a16d49f1-1d51-4581-e324-4d84fa45e4ec"
   },
   "outputs": [],
   "source": [
    "item_metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "rR1pp6o4gO9D",
    "outputId": "6fd42e11-9732-4b6b-822a-f50b29e0b5c2"
   },
   "outputs": [],
   "source": [
    "min(item_metrics['MAPE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "gluonts_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

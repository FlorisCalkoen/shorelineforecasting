{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "sB88w4AWttXV",
    "outputId": "7d2870f4-5490-415b-9d4b-0fb59907b52c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    " from google.colab import drive\n",
    " drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "tYXV18v0t3qo",
    "outputId": "7c423792-a9cf-4043-b409-eebef53dd65e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique transects in TimeFrame 635648\n",
      "Unique transects in metadata: 635648\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tf = pd.read_csv(\"gdrive/My Drive/data/shorelines/time-series-selection.csv\")\n",
    "\n",
    "print(f\"Unique transects in TimeFrame {len(tf['transect_id'].unique())}\")\n",
    "print(f\"Unique transects in metadata: {len(metadata)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k1I-57QNuyO1"
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta, datetime\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def partial2date(number, reference_year=1984):\n",
    "  year = reference_year + int(number)\n",
    "  d = timedelta(days=(reference_year + number - year)*365)\n",
    "  day_one = datetime(year, 1, 1)\n",
    "  date = d + day_one\n",
    "  return date\n",
    "\n",
    "def partials2dates(list_of_part_dates):\n",
    "  return [partial2date(idx) for idx in list_of_part_dates]\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "tf['dt'] = partials2dates(tf['dt'])\n",
    "tf = tf.set_index('dt')\n",
    "tf = tf.groupby(['transect_id', tf.index.year]).mean().reset_index()\n",
    "tf = tf.pivot(index='transect_id', columns='dt', values='dist')\n",
    "# tf.to_csv(\"gdrive/My Drive/data/shorelines/time-series-gluonts-prepared.csv\", index=True, header=True)\n",
    "tf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t49eoOlISE5u"
   },
   "outputs": [],
   "source": [
    "tf = pd.read_csv(\"gdrive/My Drive/data/shorelines/time-series-gluonts-prepared.csv\")\n",
    "tf.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep metadata which is in TimeFrame\n",
    "print(f\"Transects in TimeFrame: {len(tf['transect_id'].unique())}\")\n",
    "metadata = pd.read_pickle(\"gdrive/My Drive/data/shorelines/sites-compressed.pkl\")\n",
    "metadata = metadata.loc[metadata['transect_id'].isin(list(tf['transect_id'].unique()))]\n",
    "print(f\"Transects in Metadata: {len(metadata['transect_id'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop redundant columns (i.e., time series data)\n",
    "metadata = metadata.drop(columns=['outliers_1', 'outliers_2', 'dt', 'dist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635551\n"
     ]
    }
   ],
   "source": [
    "# drop rows without lon/lat \n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "def df2gdf(df):\n",
    "  crs = {\"init\": \"epsg:4326\"}\n",
    "  return gpd.GeoDataFrame(df, crs=crs, geometry=df['geometry'])\n",
    "\n",
    "print(f\"Transects in metadata: {len(metadata))}\")\n",
    "gdf = df2gdf(metadata)\n",
    "keep_indices = gdf.loc[gdf['geometry'].is_empty == False]['transect_id'].to_list()\n",
    "metadata = metadata.loc[metadata[\"transect_id\"].isin(keep_indices)]\n",
    "print(f\"Transects after dropping empty lon/lat: {len(metadata))}\")\n",
    "\n",
    "# Save as pickle to keep optimized dataframe (less memory)\n",
    "# metadata.to_picke(\"/media/storage/data/shorelines/sites-gluonts-prepared.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update TimeFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.loc[tf['transect_id'].isin(list(metadata['transect_id'].unique()))]\n",
    "\n",
    "# Save to csv\n",
    "# tf.to_csv(\"/media/storage/data/shorelines/time-series-gluonts-prepared.csv\", index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "transform_data.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
